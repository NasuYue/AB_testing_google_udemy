{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Strings In Pandas\n",
    "## About\n",
    "In the previous lesson, we learned how to use the apply(), map(), and applymap() methods to apply a function to a series. While we could certainly use these methods to clean strings in columns, pandas has built in many vectorized string methods that can perform these tasks quicker and with less keystrokes.\n",
    "\n",
    "- Cleaning column names\n",
    "- Extracting values from the start of strings\n",
    "- Extracting values from the end of strings\n",
    "\n",
    "## Goal\n",
    "In this lesson, we'll learn a couple other string cleaning tasks such as:\n",
    "- Finding specific strings or substrings in columns\n",
    "- Extracting substrings from unstructured data\n",
    "- Removing strings or substrings from a series\n",
    "\n",
    "## Dataset\n",
    "We'll work with the [2015 World Happiness Report again and additional economic data](https://www.kaggle.com/worldbank/world-development-indicators/version/2) from the World Bank. You can find the data set here. Here's a preview of the data set:\n",
    "\n",
    "Below are descriptions for the columns we'll be working with:\n",
    "\n",
    "- `ShortName` - Name of the country\n",
    "- `Region` - The region the country belongs to\n",
    "- `IncomeGroup` - The income group the country belongs to, based on Gross National Income (GNI) per capita\n",
    "- `CurrencyUnit` - Name of country's currency\n",
    "- `SourceOfMostRecentIncomeAndExpenditureData` - The name of the survey used to collect the income and expenditure data\n",
    "- `SpecialNotes` - Contains any miscellaneous notes about the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction\n",
    "We've already read `World_Happiness_2015.csv` into a dataframe called `happiness2015` and `World_dev.csv` into a dataframe called `world_dev`.\n",
    "\n",
    "1. Use the `pd.merge()` function to combine `happiness2015` and `world_dev`. Save the resulting dataframe to merged. As a reminder, you can use the following syntax to combine the dataframes: `pd.merge(left=df1, right=df2, how='left', left_on='left_df_Column_Name', right_on='right_df_Column_Name')`.\n",
    "    - Set the left_on parameter to the `Country` column from `happiness2015` and the `right_on` parameter to the `ShortName` column from `world_dev`.\n",
    "2. Use the `DataFrame.rename(`) method to rename the `SourceOfMostRecentIncomeAndExpenditureData` column in merged to `IESurvey` (because we don't want to keep typing that long name!).\n",
    "    - We've already saved the mapping to a dictionary named `col_renaming`.\n",
    "    - Make sure to set the `axis` parameter to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "happiness2015 = pd.read_csv(\"World_Happiness_2015.csv\")\n",
    "world_dev = pd.read_csv(\"World_dev.csv\")\n",
    "col_renaming = {'SourceOfMostRecentIncomeAndExpenditureData': 'IESurvey'}\n",
    "merged=pd.merge(left=happiness2015, right=world_dev, how='left', left_on='Country' ,right_on='ShortName')\n",
    "merged=merged.rename(col_renaming,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using Apply to Transform Strings\n",
    "Let's work with the CurrencyUnit column first. Suppose we wanted to extract the unit of currency without the leading nationality. For example, instead of \"Danish krone\" or \"Norwegian krone\", we just needed \"krone\".\n",
    "\n",
    "If we wanted to complete this task for just one of the strings, we could use Python's string.split() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_last_word(element):\n",
    "    return str(element).split()[-1]\n",
    "merged['Currency Apply'] = merged['CurrencyUnit'].apply(extract_last_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Vectorized String Methods Overview\n",
    "we could've split each element in the `CurrencyUnit` column into a list of strings with the `Series.str.split()` method, the vectorized equivalent of Python's `string.split()` method:\n",
    "- Use the `Series.str.split()` method to split the CurrencyUnit column into a list of words and then use the `Series.str.get()` method to select just the last word. Assign the result to `merged['Currency Vectorized']`.\n",
    "- Use the `Series.head()` method to print the first five rows in `merged['Currency Vectorized']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     franc\n",
       "1     krona\n",
       "2     krone\n",
       "3     krone\n",
       "4    dollar\n",
       "Name: Currency Vectorized, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged['Currency Vectorized']=merged['CurrencyUnit'].str.split().str.get(-1)\n",
    "merged['Currency Vectorized'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exploring Missing Values with Vectorized String Methods\n",
    "\n",
    "1. Use the `Series.str.len()` method to return the length of each element in the `CurrencyUnit` column. Assign the result to `lengths`.\n",
    "2. Use the `Series.value_counts()` method to return the count of unique values in `lengths`. Set the dropna parameter to False so NaNs are counted, too. Assign the result to `value_counts`.\n",
    "   - If `value_counts` contains NaNs, it means the `Series.str.len()` method excluded them and didn't treat them as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths=merged['CurrencyUnit'].str.len()\n",
    "value_counts=lengths.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Finding Specific Words in Strings\n",
    "\n",
    "We've already saved the regex to a variable called pattern. The brackets, [], indicate that either \"national accounts\" or \"National accounts\" should produce a match.\n",
    "\n",
    "- Use the `Series.str.contains()` method to search for pattern in the SpecialNotes column. Assign the result to `national_accounts`.\n",
    "- Use the `Series.head()` method to print the first five rows in `national_accounts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4      True\n",
       "       ... \n",
       "153    True\n",
       "154     NaN\n",
       "155     NaN\n",
       "156     NaN\n",
       "157    True\n",
       "Name: SpecialNotes, Length: 158, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"[Nn]ational accounts\"\n",
    "national_accounts=merged['SpecialNotes'].str.contains(pattern)\n",
    "national_accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Finding Specific Words in Strings Continued\n",
    "1. Use the `Series.str.contains()` method to search for pattern in the `SpecialNotes` column again. This time, also pass in the `na` parameter and set it to `False`. Assign the result to `national_accounts`.\n",
    "2. Use `national_accounts` to index `merged`, so that only rows that contain \"national accounts\" or \"National accounts\" in the `SpecialNotes` column are returned. Assign the result to `merged_national_accounts`.\n",
    "3. Use the `DataFrame.head()` method to print the first five rows in `merged_national_accounts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region_x</th>\n",
       "      <th>Happiness Rank</th>\n",
       "      <th>Happiness Score</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>Economy (GDP per Capita)</th>\n",
       "      <th>Family</th>\n",
       "      <th>Health (Life Expectancy)</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Trust (Government Corruption)</th>\n",
       "      <th>...</th>\n",
       "      <th>LatestPopulationCensus</th>\n",
       "      <th>LatestHouseholdSurvey</th>\n",
       "      <th>IESurvey</th>\n",
       "      <th>VitalRegistrationComplete</th>\n",
       "      <th>LatestAgriculturalCensus</th>\n",
       "      <th>LatestIndustrialData</th>\n",
       "      <th>LatestTradeData</th>\n",
       "      <th>LatestWaterWithdrawalData</th>\n",
       "      <th>Currency Apply</th>\n",
       "      <th>Currency Vectorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>5</td>\n",
       "      <td>7.427</td>\n",
       "      <td>0.03553</td>\n",
       "      <td>1.32629</td>\n",
       "      <td>1.32261</td>\n",
       "      <td>0.90563</td>\n",
       "      <td>0.63297</td>\n",
       "      <td>0.32957</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Labor force survey (LFS), 2010</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>dollar</td>\n",
       "      <td>dollar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>8</td>\n",
       "      <td>7.364</td>\n",
       "      <td>0.03157</td>\n",
       "      <td>1.33171</td>\n",
       "      <td>1.28907</td>\n",
       "      <td>0.91087</td>\n",
       "      <td>0.65980</td>\n",
       "      <td>0.43844</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Income survey (IS), 2005</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>krona</td>\n",
       "      <td>krona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Australia and New Zealand</td>\n",
       "      <td>9</td>\n",
       "      <td>7.286</td>\n",
       "      <td>0.03371</td>\n",
       "      <td>1.25018</td>\n",
       "      <td>1.31967</td>\n",
       "      <td>0.90837</td>\n",
       "      <td>0.63938</td>\n",
       "      <td>0.42922</td>\n",
       "      <td>...</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2012</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>dollar</td>\n",
       "      <td>dollar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Australia and New Zealand</td>\n",
       "      <td>10</td>\n",
       "      <td>7.284</td>\n",
       "      <td>0.04083</td>\n",
       "      <td>1.33358</td>\n",
       "      <td>1.30923</td>\n",
       "      <td>0.93156</td>\n",
       "      <td>0.65124</td>\n",
       "      <td>0.35637</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Expenditure survey/budget survey (ES/BS), 2003</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>dollar</td>\n",
       "      <td>dollar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>United States</td>\n",
       "      <td>North America</td>\n",
       "      <td>15</td>\n",
       "      <td>7.119</td>\n",
       "      <td>0.03839</td>\n",
       "      <td>1.39451</td>\n",
       "      <td>1.24711</td>\n",
       "      <td>0.86179</td>\n",
       "      <td>0.54604</td>\n",
       "      <td>0.15890</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Labor force survey (LFS), 2010</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2012</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>dollar</td>\n",
       "      <td>dollar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Country                   Region_x  Happiness Rank  Happiness Score  \\\n",
       "4          Canada              North America               5            7.427   \n",
       "7          Sweden             Western Europe               8            7.364   \n",
       "8     New Zealand  Australia and New Zealand               9            7.286   \n",
       "9       Australia  Australia and New Zealand              10            7.284   \n",
       "14  United States              North America              15            7.119   \n",
       "\n",
       "    Standard Error  Economy (GDP per Capita)   Family  \\\n",
       "4          0.03553                   1.32629  1.32261   \n",
       "7          0.03157                   1.33171  1.28907   \n",
       "8          0.03371                   1.25018  1.31967   \n",
       "9          0.04083                   1.33358  1.30923   \n",
       "14         0.03839                   1.39451  1.24711   \n",
       "\n",
       "    Health (Life Expectancy)  Freedom  Trust (Government Corruption)  ...  \\\n",
       "4                    0.90563  0.63297                        0.32957  ...   \n",
       "7                    0.91087  0.65980                        0.43844  ...   \n",
       "8                    0.90837  0.63938                        0.42922  ...   \n",
       "9                    0.93156  0.65124                        0.35637  ...   \n",
       "14                   0.86179  0.54604                        0.15890  ...   \n",
       "\n",
       "    LatestPopulationCensus  LatestHouseholdSurvey  \\\n",
       "4                     2011                    NaN   \n",
       "7                     2011                    NaN   \n",
       "8                     2013                    NaN   \n",
       "9                     2011                    NaN   \n",
       "14                    2010                    NaN   \n",
       "\n",
       "                                          IESurvey VitalRegistrationComplete  \\\n",
       "4                   Labor force survey (LFS), 2010                       Yes   \n",
       "7                         Income survey (IS), 2005                       Yes   \n",
       "8                                              NaN                       Yes   \n",
       "9   Expenditure survey/budget survey (ES/BS), 2003                       Yes   \n",
       "14                  Labor force survey (LFS), 2010                       Yes   \n",
       "\n",
       "   LatestAgriculturalCensus LatestIndustrialData LatestTradeData  \\\n",
       "4                      2011               2011.0          2013.0   \n",
       "7                      2010               2010.0          2013.0   \n",
       "8                      2012               2010.0          2013.0   \n",
       "9                      2011               2011.0          2013.0   \n",
       "14                     2012               2008.0          2013.0   \n",
       "\n",
       "   LatestWaterWithdrawalData Currency Apply Currency Vectorized  \n",
       "4                     1986.0         dollar              dollar  \n",
       "7                     2007.0          krona               krona  \n",
       "8                     2002.0         dollar              dollar  \n",
       "9                     2000.0         dollar              dollar  \n",
       "14                    2005.0         dollar              dollar  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r\"[Nn]ational accounts\"\n",
    "national_accounts=merged['SpecialNotes'].str.contains(pattern,na=False)\n",
    "merged_national_accounts=merged[national_accounts]\n",
    "merged_national_accounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Extracting Substrings From a Series\n",
    "- Create a regular expression that will match years and assign it to the variable `pattern`.\n",
    "- Use pattern and the `Series.str.extract()` method to extract years from the `SpecialNotes` column. Assign the resulting Series to `years`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0\n",
      "0     NaN\n",
      "1     NaN\n",
      "2     NaN\n",
      "3     NaN\n",
      "4     NaN\n",
      "..    ...\n",
      "153  2006\n",
      "154   NaN\n",
      "155   NaN\n",
      "156   NaN\n",
      "157  2013\n",
      "\n",
      "[158 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "pattern=r\"([1-2][0-9]{3})\"\n",
    "years=merged['SpecialNotes'].str.extract(pattern)\n",
    "print(years)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Extracting Substrings From a Series Continued\n",
    "### 9. Extracting All Matches of a Pattern From a Series\n",
    "- the `Series.str.extract()` method will only extract the first match of the pattern. If we wanted to extract all of the matches, we can use the `Series.str.extractall()` method.\n",
    "- Using a named capturing group means that we can refer to the group by the specified name instead of just a number. We can use the following syntax to add a name:` (?P<Column_Name>...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r\"(?P<Years>[1-2][0-9]{3})\"\n",
    "years=merged['IESurvey'].str.extractall(pattern)\n",
    "value_counts=years['Years'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Extracting More Than One Group of Patterns From a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6b18f8a47c1ddfb9c333eb089a621eab8f433ff0c3e2037c4d6822505db78db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
